{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whoosh Index Build Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Gamer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Gamer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\Gamer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Python 3.6.7 :: Anaconda custom (64-bit)\n",
    "#Whoosh 2.7.4_py36_1\n",
    "\n",
    "import os.path\n",
    "import codecs\n",
    "import pandas as pd\n",
    "\n",
    "from whoosh import fields, index\n",
    "from whoosh.index import create_in\n",
    "from whoosh.fields import Schema, TEXT, KEYWORD, ID, STORED\n",
    "from whoosh.analysis import StemmingAnalyzer\n",
    "from whoosh import qparser\n",
    "from whoosh.qparser import QueryParser\n",
    "from whoosh.filedb.filestore import FileStorage\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')\n",
    "from nltk.corpus import brown\n",
    "from nltk import bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Import Brown Corpus into Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>category</th>\n",
       "      <th>sentence</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b100</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca01</td>\n",
       "      <td>news</td>\n",
       "      <td>The Fulton County Grand Jury said Friday an in...</td>\n",
       "      <td>[The, Fulton, County, Grand, Jury, said, Frida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ca01</td>\n",
       "      <td>news</td>\n",
       "      <td>The jury further said in term-end presentments...</td>\n",
       "      <td>[The, jury, further, said, in, term-end, prese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ca01</td>\n",
       "      <td>news</td>\n",
       "      <td>The September-October term jury had been charg...</td>\n",
       "      <td>[The, September-October, term, jury, had, been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ca01</td>\n",
       "      <td>news</td>\n",
       "      <td>`` Only a relative handful of such reports was...</td>\n",
       "      <td>[``, Only, a, relative, handful, of, such, rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ca01</td>\n",
       "      <td>news</td>\n",
       "      <td>The jury said it did find that many of Georgia...</td>\n",
       "      <td>[The, jury, said, it, did, find, that, many, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file category                                           sentence  \\\n",
       "b100                                                                     \n",
       "0     ca01     news  The Fulton County Grand Jury said Friday an in...   \n",
       "1     ca01     news  The jury further said in term-end presentments...   \n",
       "2     ca01     news  The September-October term jury had been charg...   \n",
       "3     ca01     news  `` Only a relative handful of such reports was...   \n",
       "4     ca01     news  The jury said it did find that many of Georgia...   \n",
       "\n",
       "                                                  words  \n",
       "b100                                                     \n",
       "0     [The, Fulton, County, Grand, Jury, said, Frida...  \n",
       "1     [The, jury, further, said, in, term-end, prese...  \n",
       "2     [The, September-October, term, jury, had, been...  \n",
       "3     [``, Only, a, relative, handful, of, such, rep...  \n",
       "4     [The, jury, said, it, did, find, that, many, o...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build dataframe for the brown corpus\n",
    "fileids = brown.fileids()\n",
    "file_list = []\n",
    "cat_list = []\n",
    "sent_list = []\n",
    "word_list = []\n",
    "for file in fileids:\n",
    "    for sentence in brown.tagged_sents(tagset='universal', fileids = [file]):\n",
    "        file_list.append(file)\n",
    "        cat_list.append(brown.categories(fileids = [file])[0])\n",
    "        words = []\n",
    "        for tup in sentence:\n",
    "            words.append(tup[0])\n",
    "        sent_list.append(' '.join(words))\n",
    "        word_list.append(words)\n",
    "    \n",
    "data = pd.DataFrame({'file':file_list,'category':cat_list, 'sentence':sent_list, 'words':word_list})\n",
    "data.index.name = 'b100'\n",
    "data.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Index the Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the search schema\n",
    "schema = fields.Schema(\n",
    "    b100 = fields.ID(stored=True),\n",
    "    file = fields.TEXT(stored=True),\n",
    "    category = fields.TEXT(stored=True),\n",
    "    sentence = fields.TEXT(stored=True),\n",
    "    words = fields.KEYWORD(stored=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566cf2579d6b4dbea027e04152eaf4e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# add dataframe rows to the index\n",
    "if not os.path.exists(\"index\"):\n",
    "    os.mkdir(\"index\")\n",
    "ix = create_in(\"index\", schema)\n",
    "with ix.writer() as w:\n",
    "    for i,nrows in tqdm_notebook(data.iterrows()):\n",
    "        w.add_document(b100 = str(i),\n",
    "                       file = data.file[i],\n",
    "                       category = data.category[i],\n",
    "                       sentence = data.sentence[i],\n",
    "                       words = data.words[i],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manage index for use later\n",
    "storage = FileStorage(\"index\")\n",
    "\n",
    "# Create an index\n",
    "#ix = storage.create_index(myschema)\n",
    "\n",
    "# Open an existing index\n",
    "storage.open_index();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Head over to the search notebook to use the index.  \n",
    "\n",
    "whoosh_search_brown.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
